{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEMPERATURE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 17:28:22.911850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743092902.986373   46199 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743092903.008564   46199 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-27 17:28:23.155843: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-27 17:28:45.437049: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "129/129 - 9s - 67ms/step - loss: 0.0224 - val_loss: 0.0090\n",
      "Epoch 2/50\n",
      "129/129 - 5s - 42ms/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 3/50\n",
      "129/129 - 5s - 40ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 4/50\n",
      "129/129 - 5s - 39ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "129/129 - 5s - 39ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "129/129 - 5s - 41ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "129/129 - 5s - 40ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "129/129 - 5s - 41ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "129/129 - 5s - 40ms/step - loss: 0.0011 - val_loss: 9.4826e-04\n",
      "Epoch 10/50\n",
      "129/129 - 5s - 39ms/step - loss: 9.8032e-04 - val_loss: 8.0796e-04\n",
      "Epoch 11/50\n",
      "129/129 - 5s - 41ms/step - loss: 9.7601e-04 - val_loss: 7.4899e-04\n",
      "Epoch 12/50\n",
      "129/129 - 5s - 41ms/step - loss: 9.0079e-04 - val_loss: 7.7158e-04\n",
      "Epoch 13/50\n",
      "129/129 - 5s - 42ms/step - loss: 8.6419e-04 - val_loss: 9.0265e-04\n",
      "Epoch 14/50\n",
      "129/129 - 5s - 39ms/step - loss: 8.4166e-04 - val_loss: 6.7167e-04\n",
      "Epoch 15/50\n",
      "129/129 - 5s - 42ms/step - loss: 8.1012e-04 - val_loss: 7.6170e-04\n",
      "Epoch 16/50\n",
      "129/129 - 5s - 40ms/step - loss: 8.0512e-04 - val_loss: 6.4776e-04\n",
      "Epoch 17/50\n",
      "129/129 - 5s - 42ms/step - loss: 7.8311e-04 - val_loss: 6.2610e-04\n",
      "Epoch 18/50\n",
      "129/129 - 5s - 41ms/step - loss: 7.4967e-04 - val_loss: 6.2576e-04\n",
      "Epoch 19/50\n",
      "129/129 - 5s - 42ms/step - loss: 7.9483e-04 - val_loss: 6.2064e-04\n",
      "Epoch 20/50\n",
      "129/129 - 5s - 41ms/step - loss: 6.9866e-04 - val_loss: 6.4764e-04\n",
      "Epoch 21/50\n",
      "129/129 - 5s - 41ms/step - loss: 7.1248e-04 - val_loss: 7.3175e-04\n",
      "Epoch 22/50\n",
      "129/129 - 5s - 39ms/step - loss: 7.4540e-04 - val_loss: 6.0297e-04\n",
      "Epoch 23/50\n",
      "129/129 - 5s - 40ms/step - loss: 7.2341e-04 - val_loss: 5.9487e-04\n",
      "Epoch 24/50\n",
      "129/129 - 5s - 39ms/step - loss: 6.6484e-04 - val_loss: 6.9872e-04\n",
      "Epoch 25/50\n",
      "129/129 - 5s - 39ms/step - loss: 7.0049e-04 - val_loss: 7.8614e-04\n",
      "Epoch 26/50\n",
      "129/129 - 5s - 39ms/step - loss: 7.0040e-04 - val_loss: 5.8229e-04\n",
      "Epoch 27/50\n",
      "129/129 - 5s - 39ms/step - loss: 6.7112e-04 - val_loss: 6.3719e-04\n",
      "Epoch 28/50\n",
      "129/129 - 5s - 39ms/step - loss: 6.8535e-04 - val_loss: 8.0308e-04\n",
      "Epoch 29/50\n",
      "129/129 - 5s - 39ms/step - loss: 6.6017e-04 - val_loss: 7.2492e-04\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f64a3f8ae90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_dataset(dataset, look_back=72):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        dataX.append(dataset[i:(i + look_back), 0])\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"H_20_latest-2024-2025.csv\", sep=\";\")\n",
    "selected_columns = ['AAAAMMJJHH', 'T', 'RR1', 'NUM_POSTE', 'LAT', 'LON', 'N', 'FF', 'U', 'PSTAT']  \n",
    "df = data[selected_columns].copy()\n",
    "\n",
    "# 处理时间格，选取云量 N、风速 FF、湿度 U、检测点气压 PSTAT、温度 T、降水量 RR1来预测降水率RR3（数据没有RR3）?\n",
    "df['AAAAMMJJHH'] = pd.to_datetime(df['AAAAMMJJHH'], format='%Y%m%d%H')\n",
    "df.rename(columns={'AAAAMMJJHH': 'date', 'T': 'temperature', 'RR1': 'rainfall', \n",
    "                   'N': 'cloud_cover', 'FF': 'wind_speed', 'U': 'humidity', 'PSTAT': 'pressure'}, inplace=True)\n",
    "\n",
    "# 选择站点数据\n",
    "df = df.loc[df['NUM_POSTE'] == 20004002]\n",
    "df.set_index('date', inplace=True)\n",
    "df.interpolate(method='linear', inplace=True)  # 填充缺失值\n",
    "\n",
    "# 数据归一化\n",
    "scaler_temp = MinMaxScaler()\n",
    "df['temperature_scaled'] = scaler_temp.fit_transform(df[['temperature']])\n",
    "scaler_rain = MinMaxScaler()\n",
    "df['rainfall_scaled'] = scaler_rain.fit_transform(df[['rainfall']])\n",
    "scaler_humidity = MinMaxScaler()\n",
    "df['humidity_scaled'] = scaler_humidity.fit_transform(df[['humidity']])\n",
    "scaler_wind = MinMaxScaler()\n",
    "df['wind_speed_scaled'] = scaler_wind.fit_transform(df[['wind_speed']])\n",
    "scaler_pressure = MinMaxScaler()\n",
    "df['pressure_scaled'] = scaler_pressure.fit_transform(df[['pressure']])\n",
    "\n",
    "data_scaled = df[['temperature_scaled']].values\n",
    "X, y = create_dataset(data_scaled, look_back=72)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Train LSTM Model (Optimized)\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = Sequential([\n",
    "    LSTM(50, input_shape=(X.shape[1], X.shape[2])),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "model.fit(trainX, trainY, epochs=50, batch_size=64, validation_data=(testX, testY), verbose=2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLUIE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE  # 解决类别不均衡\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"H_20_latest-2024-2025.csv\", sep=\";\")\n",
    "selected_columns = ['AAAAMMJJHH', 'T', 'RR1', 'NUM_POSTE', 'LAT', 'LON', 'N', 'FF', 'U', 'PSTAT']\n",
    "df = data[selected_columns].copy()\n",
    "\n",
    "# 处理时间\n",
    "df['AAAAMMJJHH'] = pd.to_datetime(df['AAAAMMJJHH'], format='%Y%m%d%H')\n",
    "df.rename(columns={'AAAAMMJJHH': 'date', 'T': 'temperature', 'RR1': 'rainfall', \n",
    "                   'N': 'cloud_cover', 'FF': 'wind_speed', 'U': 'humidity', 'PSTAT': 'pressure'}, inplace=True)\n",
    "\n",
    "# 选择特定站点\n",
    "df = df.loc[df['NUM_POSTE'] == 20004002]\n",
    "df.set_index('date', inplace=True)\n",
    "df.interpolate(method='linear', inplace=True)  # 线性填充缺失值\n",
    "\n",
    "# **新增特征**（过去3小时累积降水量）\n",
    "df['rainfall_3h'] = df['rainfall'].rolling(window=3, min_periods=1).sum()\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler()\n",
    "for col in ['temperature', 'rainfall', 'cloud_cover', 'wind_speed', 'humidity', 'pressure', 'rainfall_3h']:\n",
    "    df[f'{col}_scaled'] = scaler.fit_transform(df[[col]])\n",
    "\n",
    "# **构建二分类目标变量**\n",
    "df['rain_binary'] = (df['rainfall'] > 0).astype(int)  # 0 = 无降水，1 = 有降水\n",
    "\n",
    "# **特征选择**\n",
    "features = df[['temperature_scaled', 'cloud_cover_scaled', 'wind_speed_scaled', \n",
    "               'humidity_scaled', 'pressure_scaled', 'rainfall_3h_scaled']].values\n",
    "target = df['rain_binary'].values  # 目标变量（降水 or 无降水）\n",
    "\n",
    "# **解决类别不均衡**\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)  # 生成少数类别样本\n",
    "X_resampled, y_resampled = smote.fit_resample(features, target)\n",
    "\n",
    "# **拆分数据集**\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# **优化 XGBoost 分类器**\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    scale_pos_weight=5,   # 调整类别权重\n",
    "    colsample_bytree=0.8,\n",
    "    learning_rate=0.02,  # 降低学习率\n",
    "    max_depth= 8,     \n",
    "    n_estimators=100,    # 增加迭代次数\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred_prob = xgb_model.predict_proba(X_test)[:, 1]  # 获取降水概率\n",
    "y_pred = (y_pred_prob > 0.4).astype(int)  # **降低阈值，提高降水预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
