version: "3.8"

networks:
  pipeline-net:
    driver: bridge

services:

  #-------------------------------------------------------
  # Kafka & Zookeeper
  #-------------------------------------------------------

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: ter_zookeeper
    ports:
      - "2181:2181"
    volumes:
      - ter_zookeeper_data:/data
      - ./logs/ter_zookeeper_datalog:/datalog
    networks:
      - pipeline-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 5s
      timeout: 5s
      retries: 3

  kafka:
    image: wurstmeister/kafka
    container_name: ter_kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=ter_zookeeper:2181
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://ter_kafka:9092
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
    volumes:
      - ter_kafka_data:/var/lib/kafka
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--list", "--bootstrap-server", "localhost:9092"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - pipeline-net
    depends_on:
      zookeeper:
        condition: service_healthy

  # [TODO : this logic is too random] Init Kafka Topics 
  # weather-real-time : 3 partitions & 2 hours retention
  # weather-climatologique : 2 partitions & 7 days retention
  # weather-alerts : 2 partitions & 1 day retention
  kafka-topic-init:
    image: wurstmeister/kafka
    container_name: kafka_topic_initializer
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - pipeline-net
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=ter_zookeeper:2181
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--list", "--zookeeper", "ter_zookeeper:2181"]
      interval: 5s
      timeout: 10s
      retries: 3
    restart: "no"
    entrypoint: >
      sh -c "
      echo 'Waiting for Kafka to be ready...';
      until kafka-topics.sh --list --zookeeper ter_zookeeper:2181; do
        echo 'Kafka is not ready yet, retrying in 5 seconds...';
        sleep 5;
      done;

      echo 'Creating topics...';

      kafka-topics.sh --create --topic weather-real-time --zookeeper ter_zookeeper:2181 --partitions 3 --replication-factor 1;
      kafka-configs.sh --zookeeper ter_zookeeper:2181 --entity-type topics --entity-name weather-real-time \
        --alter --add-config retention.ms=7200000,compression.type=snappy;

      kafka-topics.sh --create --topic weather-verified --zookeeper ter_zookeeper:2181 --partitions 2 --replication-factor 1;
      kafka-configs.sh --zookeeper ter_zookeeper:2181 --entity-type topics --entity-name weather-verified \
        --alter --add-config retention.ms=604800000;

      kafka-topics.sh --create --topic weather-alerts --zookeeper ter_zookeeper:2181 --partitions 2 --replication-factor 1;
      kafka-configs.sh --zookeeper ter_zookeeper:2181 --entity-type topics --entity-name weather-alerts \
        --alter --add-config retention.ms=86400000;

      echo 'Topics successfully created.';
      touch /topics_initialized;
      "

  kafka-ui:
    container_name: ter_kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: "weather-cluster"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "ter_kafka:9092"
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - pipeline-net
    restart: unless-stopped

  #-------------------------------------------------------
  # Databases
  #-------------------------------------------------------

  mongodb:
    image: mongo:5.0
    container_name: ter_mongodb
    ports:
      - "35000:35000"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
    volumes:
      - ter_mongodb_data:/data/db
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - pipeline-net
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 5s
      timeout: 5s
      retries: 3

  redis:
    image: redis:latest
    container_name: ter_redis
    ports:
      - "6379:6379"
    restart: unless-stopped
    command: ["redis-server", "--requirepass", "${REDIS_PASSWORD}"]
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 5s
      timeout: 5s
      retries: 3
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - pipeline-net

  #-------------------------------------------------------
  # API Producers
  #-------------------------------------------------------

  api_observations_producer:
    build:
      context: ./services/api_observations_producer
    container_name: ter_api_observations_producer
    volumes:
      - ./services/api_observations_producer:/app
      - ./logs/api_observations:/app/logs
      - ./services/utils/batches.json:/app/utils/batches.json
    environment:
      - KAFKA_BROKER=${KAFKA_BROKER}
      - API_TOKEN=${API_TOKEN_OBS}
    depends_on:
      kafka-topic-init:
        condition: service_healthy
    networks:
      - pipeline-net

  api_climatologique_producer:
    build:
      context: ./services/api_climatologique_producer
    container_name: ter_api_climatologique_producer
    volumes:
      - ./services/api_climatologique_producer:/app
      - ./logs/climatologique:/app/logs
      - ./services/utils/batches_corse.json:/app/utils/batches_corse.json
    environment:
      - KAFKA_BROKER=${KAFKA_BROKER}
      - API_TOKEN=${API_TOKEN_CLIMA}
    depends_on:
      kafka-topic-init:
        condition: service_healthy
    networks:
      - pipeline-net

  api_vigilance_producer:
    build:
      context: ./services/api_vigilance_producer
    container_name: ter_api_vigilance_producer
    volumes:
      - ./services/api_vigilance_producer:/app
      - ./logs/vigilance:/app/logs
    environment:
      - KAFKA_BROKER=${KAFKA_BROKER}
      - API_TOKEN=${API_TOKEN_VIGILANCE}
    depends_on:
      kafka-topic-init:
        condition: service_healthy
    networks:
      - pipeline-net

  #-------------------------------------------------------
  # Consumers
  #-------------------------------------------------------

  # mongo_consumer:
  #   build:
  #     context: ./services/mongo_consumer
  #   container_name: ter_mongo_consumer
  #   volumes:
  #     - ./services/mongo_consumer:/app
  #   environment:
  #     - MONGO_URI=${MONGO_URI}
  #     - KAFKA_BROKER=${KAFKA_BROKER}
  #   depends_on:
  #     - kafka
  #     - mongo
  #   networks:
  #     - pipeline-net

  redis_consumer:
    build:
      context: ./services/redis_consumer
    container_name: ter_redis_consumer
    volumes:
      - ./services/redis_consumer:/app
      - ./logs/redis:/app/logs
    environment:
      - REDIS_HOST=ter_redis
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_PORT=6379
      - KAFKA_BROKER=${KAFKA_BROKER}
      - KAFKA_TOPICS=weather-real-time,weather-alerts
    depends_on:
      kafka-topic-init:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - pipeline-net


  #-------------------------------------------------------
  # GRAFANA & its Datasources
  #-------------------------------------------------------

  grafana:
    image: grafana/grafana:latest
    container_name: ter_grafana
    ports:
      - "3000:3000"
    networks:
      - pipeline-net
    volumes:
      - ter_grafana_data:/var/lib/grafana
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
    restart: unless-stopped

  # Prometheus & its Exporters
  prometheus:
    image: prom/prometheus:latest
    container_name: ter_prometheus
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ter_prometheus_data:/prometheus
      - ./logs/prometheus:/prometheus/logs
    ports:
      - "9090:9090"
    networks:
      - pipeline-net

  prometheus-node-exporter:
    image: prom/node-exporter:latest
    container_name: ter_prometheus-node-exporter
    ports:
      - "9100:9100"
    networks:
      - pipeline-net
    restart: unless-stopped

  prometheus-mongodb-exporter:
    image: bitnami/mongodb-exporter:latest
    container_name: ter_prometheus-mongodb-exporter
    ports:
      - "9216:9216"
    networks:
      - pipeline-net
    environment:
      MONGODB_URI: mongodb://mongodb:27017
      MONGODB_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGODB_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
    restart: unless-stopped

  prometheus-kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    container_name: ter_prometheus-kafka-exporter
    ports:
      - "9308:9308"
    networks:
      - pipeline-net
    environment:
      KAFKA_SERVER: ter_kafka:9092
    restart: unless-stopped
  
  prometheus-redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: ter_prometheus-redis-exporter
    ports:
      - "9121:9121"
    networks:
      - pipeline-net
    environment:
      REDIS_ADDR: "ter_redis:6379" 
      REDIS_PASSWORD: "${REDIS_PASSWORD}" 
    restart: unless-stopped

  #-------------------------------------------------------
  # Client web
  #-------------------------------------------------------

  backend:
    build:
      context: ./services/backend
    container_name: ter_backend
    ports:
      - "5000:5000" 
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - MONGO_INITDB_ROOT_USERNAME= ${MONGO_INITDB_ROOT_USERNAME}
      - MONGO_INITDB_ROOT_PASSWORD= ${MONGO_INITDB_ROOT_PASSWORD}
    volumes:
      - ./services/backend:/usr/src/app
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - pipeline-net

  frontend:
    build:
      context: ./services/frontend
    container_name: ter_frontend
    ports:
      - "3001:3001" 
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:5000 
    depends_on:
      - backend
    networks:
      - pipeline-net


volumes:
  ter_mongodb_data:
  ter_kafka_data:
  ter_zookeeper_data:
  ter_zookeeper_datalog:
  ter_kafka_manager_logs:
  ter_prometheus_data:
  ter_grafana_data:

