version: "3.8"

networks:
  pipeline-net:
    driver: bridge

services:

  #-------------------------------------------------------
  # Nginx 
  #-------------------------------------------------------
  nginx:
    image: 'jc21/nginx-proxy-manager:latest'
    container_name: ter_nginx_proxy_manager
    ports:
      # ports <host-port>:<container-port>
      - '80:80' # Public HTTP Port
      - '443:443' # Public HTTPS Port
      - '81:81' # Admin Web Port
    volumes:
      - npm_data:/data #create vol in the container at /data path
      - npm_letsencrypt:/etc/letsencrypt
    
    networks:
      - pipeline-net
    restart: unless-stopped

    


  #-------------------------------------------------------
  # Kafka & Zookeeper
  #-------------------------------------------------------

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: ter_zookeeper
    ports:
      - "2181:2181"
    volumes:
      - ter_zookeeper_data:/data
      - ./logs/ter_zookeeper_datalog:/datalog
    networks:
      - pipeline-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 5s
      timeout: 5s
      retries: 3

  kafka:
    image: wurstmeister/kafka
    container_name: ter_kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=ter_zookeeper:2181
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://ter_kafka:9092
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
    volumes:
      - ter_kafka_data:/var/lib/kafka
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--list", "--bootstrap-server", "localhost:9092"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - pipeline-net
    depends_on:
      zookeeper:
        condition: service_healthy

  kafka-topic-init:
    image: wurstmeister/kafka
    container_name: kafka_topic_initializer
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - pipeline-net
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=ter_zookeeper:2181
    volumes:
      - ./infrastructure/kafka:/init_scripts  
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--list", "--bootstrap-server", "ter_kafka:9092"]
      interval: 5s
      timeout: 10s
      retries: 3
    restart: "no"
    entrypoint: ["/bin/sh", "-c", "sh /init_scripts/init_kafka_topics.sh"]

  kafka-ui:
    container_name: ter_kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: "weather-cluster"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "ter_kafka:9092"
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - pipeline-net
    restart: unless-stopped

  #-------------------------------------------------------
  # Databases
  #-------------------------------------------------------

  mongodb:
    image: mongo:5.0
    container_name: ter_mongodb
    ports:
      - "27017:27017" #
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
    volumes:
      - ter_mongodb_data:/data/db
    depends_on:
      kafka-topic-init:
        condition: service_completed_successfully
    networks:
      - pipeline-net
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 5s
      timeout: 5s
      retries: 3

  redis:
    image: redis:latest
    container_name: ter_redis
    ports:
      - "6379:6379"
    restart: unless-stopped
    command: ["redis-server", "--requirepass", "${REDIS_PASSWORD}", "--notify-keyspace-events", "KEA"]
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 5s
      timeout: 5s
      retries: 3
    depends_on:
      kafka-topic-init:
        condition: service_completed_successfully
    networks:
      - pipeline-net

  postgres:
    image: postgres:13
    container_name: ter_postgres
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - ter_postgres_data:/var/lib/postgresql/data
      - ./infrastructure/postgres:/docker-entrypoint-initdb.d
    networks:
      - pipeline-net
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}", "-d", "${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 3
  #-------------------------------------------------------
  # API Producers
  #-------------------------------------------------------

  api_observations_producer:
    build:
      context: ./services/api_observations_producer
    container_name: ter_api_observations_producer
    volumes:
      - ./services/api_observations_producer:/app
      - ./logs/api_observations:/app/logs
      - ./services/utils/batches.json:/app/utils/batches.json
    environment:
      - KAFKA_BROKER=${KAFKA_BROKER}
      - API_TOKEN=${API_TOKEN_OBS}
    depends_on:
      kafka-topic-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    networks:
      - pipeline-net
    # TEST
    # command: ["pytest", "--maxfail=5", "--disable-warnings", "-v"]

  api_climatologique_producer:
    build:
      context: ./services/api_climatologique_producer
    container_name: ter_api_climatologique_producer
    volumes:
      - ./services/api_climatologique_producer:/app
      - ./logs/climatologique:/app/logs
      - ./services/utils/batches_corse.json:/app/utils/batches_corse.json
    environment:
      - KAFKA_BROKER=${KAFKA_BROKER}
      - API_TOKEN=${API_TOKEN_CLIMA}
    depends_on:
      kafka-topic-init:
        condition: service_completed_successfully
      mongodb:
        condition: service_healthy
    networks:
      - pipeline-net

  api_vigilance_producer:
    build:
      context: ./services/api_vigilance_producer
    container_name: ter_api_vigilance_producer
    volumes:
      - ./services/api_vigilance_producer:/app
      - ./logs/vigilance:/app/logs
    environment:
      - KAFKA_BROKER=${KAFKA_BROKER}
      - API_TOKEN=${API_TOKEN_VIGILANCE}
    depends_on:
      kafka-topic-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    networks:
      - pipeline-net

  #-------------------------------------------------------
  # Consumers
  #-------------------------------------------------------

  mongo_consumer:
    build:
      context: ./services/mongo_consumer
    container_name: ter_mongo_consumer
    volumes:
      - ./services/mongo_consumer:/app
    environment:
      - KAFKA_BROKER=${KAFKA_BROKER}
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_INITDB_ROOT_USERNAME}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_INITDB_ROOT_PASSWORD}
    depends_on:
      - kafka
      - mongodb
    networks:
      - pipeline-net

  redis_consumer:
    build:
      context: ./services/redis_consumer
    container_name: ter_redis_consumer
    volumes:
      - ./services/redis_consumer:/app
      - ./logs/redis:/app/logs
    environment:
      - REDIS_HOST=ter_redis
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_PORT=6379
      - KAFKA_BROKER=${KAFKA_BROKER}
      - KAFKA_TOPICS=weather-real-time,weather-alerts
    depends_on:
      kafka-topic-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    networks:
      - pipeline-net


  #-------------------------------------------------------
  # GRAFANA & its Datasources
  #-------------------------------------------------------

  grafana:
    image: grafana/grafana:latest
    container_name: ter_grafana
    ports:
      - "3000:3000"
    networks:
      - pipeline-net
    volumes:
      - ter_grafana_data:/var/lib/grafana
      - ./infrastructure/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - ./infrastructure/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
    restart: unless-stopped

  # Prometheus & its Exporters
  prometheus:
    image: prom/prometheus:latest
    container_name: ter_prometheus
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ter_prometheus_data:/prometheus
      - ./logs/prometheus:/prometheus/logs
    ports:
      - "9090:9090"
    networks:
      - pipeline-net

  prometheus-node-exporter:
    image: prom/node-exporter:latest
    container_name: ter_prometheus-node-exporter
    ports:
      - "9100:9100"
    networks:
      - pipeline-net
    restart: unless-stopped

  prometheus-mongodb-exporter:
    image: bitnami/mongodb-exporter:latest
    container_name: ter_prometheus-mongodb-exporter
    ports:
      - "9216:9216"
    networks:
      - pipeline-net
    environment:
      MONGODB_URI: mongodb://mongodb:27017
      MONGODB_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGODB_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
    restart: unless-stopped

  prometheus-kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    container_name: ter_prometheus-kafka-exporter
    ports:
      - "9308:9308"
    networks:
      - pipeline-net
    environment:
      KAFKA_SERVER: ter_kafka:9092
    restart: unless-stopped
  
  prometheus-redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: ter_prometheus-redis-exporter
    ports:
      - "9121:9121"
    networks:
      - pipeline-net
    environment:
      REDIS_ADDR: "ter_redis:6379" 
      REDIS_PASSWORD: "${REDIS_PASSWORD}" 
    restart: unless-stopped

  cadvisor:
    image: google/cadvisor:latest
    container_name: ter_cadvisor
    ports:
      - "8090:8080" 
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
    restart: always
    privileged: true
    networks:
      - pipeline-net

  #-------------------------------------------------------
  # Client web
  #-------------------------------------------------------

  backend:
    build:
      context: ./services/backend
    container_name: ter_backend
    ports:
      - "5000:5000" 
    
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_INITDB_ROOT_USERNAME}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_INITDB_ROOT_PASSWORD}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
      - JWT_SECRET=${JWT_SECRET}
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@ter_postgres:5432/${POSTGRES_DB}
    volumes:
      - ./services/backend:/usr/src/app
      
    depends_on:
      mongodb:
        condition: service_healthy
      kafka-topic-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - pipeline-net

  frontend:
    build:
      context: ./services/frontend
    container_name: ter_frontend
    ports:
      - "3001:3001" 
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:5000 
      - PORT=3001
    volumes:
      - ./services/frontend:/usr/src/app
      - /usr/src/app/node_modules
    depends_on:
      - backend
    networks:
      - pipeline-net

volumes:
  npm_data:
  npm_letsencrypt:

  ter_mongodb_data:
  ter_kafka_data:
  ter_zookeeper_data:
  ter_zookeeper_datalog:
  ter_kafka_manager_logs:
  ter_prometheus_data:
  ter_grafana_data:
  ter_postgres_data:

